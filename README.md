

# AI Blogging Platform

An academic full‑stack project demonstrating real‑time AI assisted content generation, streaming markdown rendering, and media enrichment. Built to showcase modern web engineering patterns (streaming, modular monorepo, API design, security hardening) in a compact, production‑deployable form.

"From empty prompt to a formatted illustrated article in seconds."



---

## 1. Elevator Summary

This platform lets a user enter a topic and receive: (a) a progressively streaming 500‑word markdown article generated by an LLM, (b) contextual images fetched automatically, (c) instant persistence + detail view. It emphasizes: low-latency streaming UX, clean API boundaries, and safe integration of third‑party AI services.

## 2. Key Differentiators (10 Highlights)

1. Real‑time Server‑Sent Events (SSE) streaming (sub‑second perceived start).
2. Dual generation modes: full batch + live stream.
3. Automatic keyword extraction → image retrieval (0–3 curated images/article).
4. Clean monorepo separation (frontend / backend) with environment isolation.
5. Strict prompt validation + rate limiting (protect cost & abuse).
6. Configurable CORS with wildcard + origin normalization.
7. Security headers (Helmet), minimal attack surface, no secrets client side.
8. Extendable data model (tags, authors, drafts can be added without breaking API).
9. Framework‑agnostic REST API (5 core endpoints + health).
10. Fast local dev loop (Vite HMR + nodemon) < 1s incremental rebuild.

> Quantitative snapshot: 5 primary API endpoints, 2 generation strategies, < 70 lines core route logic, typical first stream token < 1.5s (network dependent).

## 3. System Overview

Flow: User prompt → Backend validates → Cohere streaming/batch → Keyword refinement → Unsplash lookup → Persist MongoDB (title/content/images) → Serve to frontend (markdown rendered). The split architecture enables independent scaling and swapping AI providers with minimal change (adapter boundary is the generate route).

### High-Level Architecture (Text Diagram)

```
[React SPA] --fetch--> [Express API] --LLM--> [Cohere]
      |                           \
      |                            \--(keywords)--> [Cohere]
      |                                               |
 (SSE stream) <----------------------------------  [Stream]
      |
      |                                 \-------> [Unsplash API]
      |                                               |
      |                                           [Image URLs]
      |                                        \      |
      |                                               |
     (View Stored) <--- [MongoDB (Blog docs)] <--- Save

```

## 4. Tech Stack

| Layer           | Tools                                                                    |
| --------------- | ------------------------------------------------------------------------ |
| Frontend        | React 19, Vite, TailwindCSS, Framer Motion, React Router, React Markdown |
| Backend         | Node.js, Express 5, Mongoose 8                                           |
| AI / Media      | Cohere (model: `command-r-08-2024`), Unsplash API                        |
| Security        | Helmet, Configurable CORS, Rate Limiter                                  |
| Infra (example) | Render (API), Vercel (Static SPA), MongoDB Atlas                         |

## 5. Data Model

```
Blog {
  _id: ObjectId,
  title: String,        // original prompt
  content: String,      // markdown generated
  images: [String],     // Unsplash URLs
  createdAt: Date       // index candidate
}
```

## 6. API Summary

Base: `/api/blogs`

| Method | Path             | Purpose                            |
| ------ | ---------------- | ---------------------------------- |
| GET    | /                | List blogs (reverse chronological) |
| GET    | /:id             | Retrieve a blog by id              |
| DELETE | /:id             | Remove blog                        |
| POST   | /generate        | Synchronous generate + persist     |
| POST   | /generate-stream | SSE streaming generation           |
| GET    | /health          | Service heartbeat                  |

SSE emits incremental `data:` chunks; terminates with `data: [DONE]`.

## 7. Environment Variables

Backend (`backend/.env`):

```
MONGO_URI=...            # MongoDB Atlas connection
COHERE_API_KEY=...       # Cohere model access
UNSPLASH_KEY=...         # Unsplash access key
ALLOWED_ORIGINS=...      # Comma / space separated, supports *.domain
GEN_WINDOW_MINUTES=15    # Rate limit window
GEN_MAX_REQUESTS=10      # Requests per window per IP
PORT=5000                # Local override (platform may inject)
```

Frontend (`frontend/.env`):

```
VITE_API_BASE=http://localhost:5000  # or deployed backend URL
```

## 8. Local Development (5 Steps)

1. Clone & install: `cd backend && npm install && cd ../frontend && npm install`.
2. Copy each `.env.example` → `.env` and fill keys.
3. Start backend: `npm run dev` (port 5000). Start frontend: `npm run dev`.
4. Open `http://localhost:5173` → Create page → enter topic.
5. Watch live streaming; open Network tab to observe SSE.

## 9. Deployment (Concise)

| Component | Example Platform   | Notes                                              |
| --------- | ------------------ | -------------------------------------------------- |
| API       | Render Web Service | Root Directory: `backend`, Start: `node server.js` |
| DB        | MongoDB Atlas      | Shared free tier sufficient for demo               |
| Frontend  | Vercel Static      | Root: `frontend`, set `VITE_API_BASE`              |

Post‑deploy smoke test: `GET <api>/health` (200), Frontend loads recent blogs, streaming works.

## 10. Security & Reliability Measures

| Measure                   | Motivation                     |
| ------------------------- | ------------------------------ |
| Helmet headers            | Baseline hardening             |
| Origin‑aware CORS         | Prevent unauthorized embedding |
| Prompt length validation  | Cost control & input sanity    |
| Rate limiting (AI routes) | Abuse mitigation               |
| Env isolation             | No secrets in bundle           |
| Structured 404 & health   | Ops visibility                 |

## 11. Extension Ideas (Research / Future Work)

| Track           | Idea                                | Rationale                      |
| --------------- | ----------------------------------- | ------------------------------ |
| NLP             | Multi‑model A/B (Cohere vs OpenAI)  | Quality benchmarking           |
| Personalization | User accounts & history weighting   | Adaptive generation            |
| Retrieval       | Vector search for factual grounding | Reduce hallucination           |
| Observability   | Prometheus + dashboards             | Latency / token metrics        |
| Editorial       | Tagging, draft workflow             | Academic publishing simulation |
| Export          | PDF / EPUB builder                  | Academic dissemination         |

## 12. Performance Considerations

Lightweight backend (few dependencies). Streaming reduces perceived latency vs. waiting full generation. Potential optimizations: parallel keyword + image fetch (already partial), caching image queries, adding indexes on `createdAt`.

## 13. Testing Pointers (Minimal)

| Aspect     | Quick Check                            |
| ---------- | -------------------------------------- |
| Health     | `curl /health` == 200                  |
| Generation | POST `/api/blogs/generate` with prompt |
| Streaming  | Observe incremental chunks in DevTools |
| Rate Limit | Exceed N requests → 429 JSON           |

## 14. Troubleshooting Fast Table

| Symptom          | Likely Cause     | Action                                     |
| ---------------- | ---------------- | ------------------------------------------ |
| 403 CORS         | Origin mismatch  | Adjust `ALLOWED_ORIGINS`                   |
| 500 generate     | Missing API key  | Check backend env vars                     |
| No stream        | Proxy buffering  | Confirm SSE headers, try different network |
| Empty images     | Unsplash quota   | Inspect logs / rotate key                  |
| Slow first token | Model cold start | Warm with small pre‑flight call            |

## 15. Academic Relevance

Demonstrates integration of generative AI into a full web delivery pipeline, focusing on human‑perceived latency improvement (streaming), responsible resource usage (rate limiting), and modularity for experimentation (swappable AI provider). Suitable as a capstone / coursework artifact illustrating applied software architecture + AI service orchestration.

## 16. License & Attribution

Add a license (e.g., MIT) before distributing. Acknowledge Cohere & Unsplash per their terms.

---

**Maintainer Note:** PRs adding evaluation metrics (readability scoring, factuality checks) are welcome.
